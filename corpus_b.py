# generated by chatGPT
import re
import nltk
from collections import defaultdict, Counter

nltk.download("punkt")
nltk.download("averaged_perceptron_tagger")

def add_wikipedia_article(topic):
    import wikipedia
    wikipedia.set_lang("en")
    try:
        article = wikipedia.page(topic, auto_suggest=False)
        return article.content
    except Exception as e:
        print(f"Failed to fetch article: {e}")
        return ""

text = ""
text += add_wikipedia_article("Banana (fruit)")
if not text.strip():
    print("No text fetched from Wikipedia. Check topic name or internet connection.")

def colorize(text, color="red"):
    color_codes = {
        "red": "\033[91m",
        "green": "\033[92m",
        "yellow": "\033[93m",
        "blue": "\033[94m",
        "magenta": "\033[95m",
        "cyan": "\033[96m",
        "end": "\033[0m",
    }
    return f"{color_codes.get(color, '')}{text}{color_codes['end']}"

def kwic_grouped_by_pos_and_sorted(text, search_words, window=5, color="red"):
    tokens = nltk.word_tokenize(text)
    pos_tags = nltk.pos_tag(tokens)
    target_tokens = search_words.split()
    n = len(target_tokens)

    pos_category_map = {
        'VB': 'VERBS',
        'NN': 'NOUNS',
        'JJ': 'ADJECTIVES',
    }

    grouped_kwic = defaultdict(lambda: defaultdict(list))
    freq_by_pos = defaultdict(Counter)

    for i in range(len(tokens) - n):
        if tokens[i:i + n] == target_tokens:
            next_index = i + n
            if next_index >= len(tokens):
                continue

            next_token, next_tag = pos_tags[next_index]
            pos_prefix = next_tag[:2]
            category = pos_category_map.get(pos_prefix)
            if not category:
                continue

            start = max(0, i - window)
            end = min(len(tokens), i + n + window)
            left = tokens[start:i]
            match = colorize(" ".join(tokens[i:i + n]), color)
            right = tokens[i + n:end]
            kwic_line = " ".join(left + [match] + right)

            grouped_kwic[category][next_token].append(kwic_line)
            freq_by_pos[category][next_token] += 1

    sorted_categories = sorted(
        freq_by_pos.items(),
        key=lambda item: sum(item[1].values()),
        reverse=True
    )

    for category, token_counter in sorted_categories:
        print(f"\n<{category}>")
        for next_token, _ in token_counter.most_common():
            for kwic in grouped_kwic[category][next_token]:
                print("...", kwic, "...")

def main():
    search_words = input("Please enter a search term (e.g. bananas are): ")
    window = int(input("Please enter the window size (e.g. 5): "))
    color = input("Please enter a color for the search term (e.g. red, green, yellow, blue, magenta, cyan): ")

    if text:
        kwic_grouped_by_pos_and_sorted(text, search_words, window=window, color=color)


if __name__ == "__main__":
    main()
